{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0a69b99-39cc-4e7d-b925-bb1768c3e68c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In Python, use `PolynomialFeatures` from sklearn to transform features, then apply `LinearRegression`. \\nThis allows fitting polynomial models with standard linear regression techniques.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. What is Simple Linear Regression?\n",
    "\"\"\"Simple Linear Regression is a statistical method used to model the relationship between one independent variable and one dependent variable using a straight line (Y = mX + c).\"\"\"\n",
    "\n",
    "# 2. What are the key assumptions of Simple Linear Regression?\n",
    "\"\"\"Key assumptions include linearity, independence of errors, homoscedasticity (equal variance), no multicollinearity, and normally distributed residuals. Violating these assumptions can lead to inaccurate predictions or misleading model results.\"\"\"\n",
    "\n",
    "# 3. What does the coefficient m represent in the equation Y = mX + c?\n",
    "\"\"\"The coefficient m is the slope of the regression line. It represents the change in the dependent variable Y for a one-unit change in the independent variable X.\"\"\"\n",
    "\n",
    "# 4. What does the intercept c represent in the equation Y = mX + c?\n",
    "\"\"\"The intercept c represents the predicted value of Y when X is zero. It is the point where the regression line crosses the Y-axis.\"\"\"\n",
    "\n",
    "# 5. How do we calculate the slope m in Simple Linear Regression?\n",
    "\"\"\"The slope m is calculated as the covariance of X and Y divided by the variance of X. It shows the direction and steepness of the relationship between X and Y.\"\"\"\n",
    "\n",
    "# 6. What is the purpose of the least squares method in Simple Linear Regression?\n",
    "\"\"\"The least squares method minimizes the sum of squared differences between observed and predicted values, ensuring the best-fitting line through the data points.\"\"\"\n",
    "\n",
    "# 7. How is the coefficient of determination (R²) interpreted in Simple Linear Regression?\n",
    "\"\"\"R² indicates the proportion of variance in the dependent variable explained by the independent variable. An R² of 0.8 means 80% of the variation in Y is explained by X.\"\"\"\n",
    "\n",
    "# 8. What is Multiple Linear Regression?\n",
    "\"\"\"Multiple Linear Regression models the relationship between one dependent variable and two or more independent variables using a linear equation to predict outcomes.\"\"\"\n",
    "\n",
    "# 9. What is the main difference between Simple and Multiple Linear Regression?\n",
    "\"\"\"Simple Linear Regression uses one independent variable, while Multiple Linear Regression uses two or more. \n",
    "This allows Multiple Linear Regression to capture more complex relationships.\"\"\"\n",
    "\n",
    "# 10. What are the key assumptions of Multiple Linear Regression?\n",
    "\"\"\"Assumptions include linearity, independence of errors, no multicollinearity, homoscedasticity, and normality of residuals. \n",
    "These ensure valid statistical inference and accurate predictions.\"\"\"\n",
    "\n",
    "# 11. What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression model?\n",
    "\"\"\"Heteroscedasticity occurs when residuals have unequal variance. It can distort standard errors, \n",
    "making statistical tests unreliable and affecting model interpretation and prediction accuracy.\"\"\"\n",
    "\n",
    "# 12. How can you improve a Multiple Linear Regression model with high multicollinearity?\n",
    "\"\"\"To reduce multicollinearity, remove or combine correlated predictors, use dimensionality reduction (e.g., PCA), \n",
    "or apply regularization techniques like Ridge or Lasso regression.\"\"\"\n",
    "\n",
    "# 13. What are some common techniques for transforming categorical variables for use in regression models?\n",
    "\"\"\"Common techniques include One-Hot Encoding, Label Encoding, and Binary Encoding. These convert categorical data \n",
    "into numerical format suitable for regression models.\"\"\"\n",
    "\n",
    "# 14. What is the role of interaction terms in Multiple Linear Regression?\n",
    "\"\"\"Interaction terms capture the combined effect of two or more variables on the dependent variable, \n",
    "allowing the model to account for complex relationships between predictors.\"\"\"\n",
    "\n",
    "# 15. How can the interpretation of intercept differ between Simple and Multiple Linear Regression?\n",
    "\"\"\"In Simple Linear Regression, the intercept is the expected value of Y when X is zero. In Multiple Regression, \n",
    "it's the value of Y when all predictors are zero, which may not be meaningful.\"\"\"\n",
    "\n",
    "# 16. What is the significance of the slope in regression analysis, and how does it affect predictions?\n",
    "\"\"\"The slope shows the rate of change in the dependent variable for each unit change in an independent variable. \n",
    "It directly impacts prediction accuracy and interpretation of relationships.\"\"\"\n",
    "\n",
    "# 17. How does the intercept in a regression model provide context for the relationship between variables?\n",
    "\"\"\"The intercept gives the starting point of the regression line when all predictors are zero. \n",
    "It provides a reference value to better understand variable impacts on the outcome.\"\"\"\n",
    "\n",
    "# 18. What are the limitations of using R² as a sole measure of model performance?\n",
    "\"\"\"R² doesn't indicate causation, ignores overfitting, and doesn’t account for the number of predictors. \n",
    "It may give a false impression of performance in complex or overfit models.\"\"\"\n",
    "\n",
    "# 19. How would you interpret a large standard error for a regression coefficient?\n",
    "\"\"\"A large standard error suggests the coefficient is not estimated precisely, \n",
    "indicating uncertainty in its value and reducing confidence in the predictor’s significance.\"\"\"\n",
    "\n",
    "# 20. How can heteroscedasticity be identified in residual plots, and why is it important to address it?\n",
    "\"\"\"Heteroscedasticity appears as a funnel-shaped pattern in residual plots. \n",
    "It must be addressed to ensure valid hypothesis testing and reliable confidence intervals in regression.\"\"\"\n",
    "\n",
    "# 21. What does it mean if a Multiple Linear Regression model has a high R² but low adjusted R²?\n",
    "\"\"\"It suggests that non-useful predictors were added. Adjusted R² penalizes for unnecessary variables, \n",
    "so a drop indicates they don’t improve the model’s explanatory power.\"\"\"\n",
    "\n",
    "# 22. Why is it important to scale variables in Multiple Linear Regression?\n",
    "\"\"\"Scaling ensures variables contribute equally, improving model stability and interpretation. \n",
    "It is especially important when predictors are on different scales or in regularized models.\"\"\"\n",
    "\n",
    "# 23. What is polynomial regression?\n",
    "\"\"\"Polynomial regression is an extension of linear regression where the relationship between variables is \n",
    "modeled as an nth-degree polynomial to capture curvature in data.\"\"\"\n",
    "\n",
    "# 24. How does polynomial regression differ from linear regression?\n",
    "\"\"\"Linear regression fits a straight line, while polynomial regression fits curved lines using higher-degree terms. \n",
    "It models more complex, non-linear relationships between variables.\"\"\"\n",
    "\n",
    "# 25. When is polynomial regression used?\n",
    "\"\"\"It’s used when data shows a curved trend that linear models cannot capture. It's useful for \n",
    "fitting non-linear patterns in real-world data like growth or seasonal changes.\"\"\"\n",
    "\n",
    "# 26. What is the general equation for polynomial regression?\n",
    "\"\"\"The general equation is: Y = β₀ + β₁X + β₂X² + ... + βₙXⁿ, where n is the polynomial degree and β’s are the model coefficients.\"\"\"\n",
    "\n",
    "# 27. Can polynomial regression be applied to multiple variables?\n",
    "\"\"\"Yes, multivariate polynomial regression includes polynomial terms of multiple predictors. \n",
    "It models complex interactions and non-linear relationships among multiple variables.\"\"\"\n",
    "\n",
    "# 28. What are the limitations of polynomial regression?\n",
    "\"\"\"It can overfit the data with high-degree terms, is sensitive to outliers, \n",
    "and becomes complex to interpret as polynomial degree increases. It may also generalize poorly to new data.\"\"\"\n",
    "\n",
    "# 29. What methods can be used to evaluate model fit when selecting the degree of a polynomial?\n",
    "\"\"\"Use cross-validation, Adjusted R², AIC/BIC, and residual plots to evaluate model fit and select the \n",
    "polynomial degree that balances complexity and performance.\"\"\"\n",
    "\n",
    "# 30. Why is visualization important in polynomial regression?\n",
    "\"\"\"Visualization helps detect overfitting or underfitting, understand the model's curve, and \n",
    "communicate how well the polynomial regression fits the data pattern.\"\"\"\n",
    "\n",
    "# 31. How is polynomial regression implemented in Python?\n",
    "\"\"\"In Python, use `PolynomialFeatures` from sklearn to transform features, then apply `LinearRegression`. \n",
    "This allows fitting polynomial models with standard linear regression techniques.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deac2623-8fd3-462c-a76d-084932dfbc59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348f9f42-08db-45f7-8f02-98c32cbb5612",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4820a9f4-5c90-4e20-8979-eca32aa3013d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed3b146-2a77-4464-890c-18725ca9069b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
